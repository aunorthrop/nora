<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Nora</title>
<style>
  *{margin:0;padding:0;box-sizing:border-box}
  html,body{height:100%}
  body{
    background:#0e1116;
    display:flex;align-items:center;justify-content:center;
    -webkit-user-select:none;user-select:none;
    font-family:-apple-system,BlinkMacSystemFont,"Inter",system-ui,sans-serif;
    touch-action:manipulation;
  }
  .voice-button{
    width:180px;height:180px;border:none;border-radius:28px;background:#131722;
    box-shadow:0 6px 22px rgba(0,0,0,.35), inset 0 -3px 0 rgba(255,255,255,.04);
    cursor:pointer;position:relative;display:grid;place-items:center;
    transition:transform .06s ease, box-shadow .06s ease, background .15s ease, color .15s ease;
    color:#e8e9ed;-webkit-tap-highlight-color:transparent;border:1px solid #1d2433;
  }
  .voice-button:active,.voice-button.pressed{transform:scale(.98);box-shadow:inset 0 4px 12px rgba(0,0,0,.35),0 2px 4px rgba(0,0,0,.2)}
  .voice-button.idle{background:#131722;color:#e8e9ed}
  .voice-button.listening{background:#0b5cff;color:#fff;box-shadow:0 0 0 4px rgba(11,92,255,.18), 0 10px 28px rgba(0,0,0,.45)}
  .voice-button.thinking{background:#ffd60a;color:#111}
  .voice-button.speaking{background:#18c964;color:#0b0c10}
  .voice-button.error{background:#ff3b30;color:#fff}
  .mic-icon{width:44px;height:44px;fill:currentColor}
</style>
</head>
<body>
  <!-- The ONLY visible UI -->
  <button id="voiceBtn" class="voice-button idle" aria-label="Press to talk" title="">
    <svg class="mic-icon" viewBox="0 0 24 24" aria-hidden="true">
      <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm7-3h-2a5 5 0 0 1-10 0H5a7 7 0 0 0 6 6.92V21h2v-3.08A7 7 0 0 0 19 11z"/>
    </svg>
  </button>

  <!-- scope key (kept hidden) -->
  <input id="bizId" type="hidden" value="nora"/>

<script>
(() => {
  const voiceBtn = document.getElementById('voiceBtn');
  const BIZ_ID = (document.getElementById('bizId').value || 'nora');

  // persistent lightweight memory (unchanged behavior, no UI)
  const LOCAL_KEY = `nora_voice_memory_${BIZ_ID}`;
  function loadLocal(){
    try { return JSON.parse(localStorage.getItem(LOCAL_KEY) || '{"items":[],"conversations":[],"voice":"alloy","pace":0.95,"boot":false}'); }
    catch { return { items:[], conversations:[], voice:"alloy", pace:0.95, boot:false }; }
  }
  function saveLocal(m){ try { localStorage.setItem(LOCAL_KEY, JSON.stringify(m)); } catch(e){} }
  let memoryShadow = loadLocal();
  if (!memoryShadow.conversations) memoryShadow.conversations = [];
  memoryShadow.voice = memoryShadow.voice || "alloy";
  memoryShadow.pace  = typeof memoryShadow.pace === "number" ? memoryShadow.pace : 0.95;
  saveLocal(memoryShadow);

  // state
  let isSession=false,isListening=false,isProcessing=false,isSpeaking=false;
  let sessionId=null,inflightController=null;
  let audioCtx,micStream,micRecorder,chunks=[];
  let audioProcessor,source,maxRecordTimer;
  let startedAt=0,lastNonSilenceAt=0,hasBoot=false,uiLock=false;
  const speaker = new Audio(); speaker.preload="none"; speaker.playsInline=true; speaker.volume=1.0;

  function setBtnState(cls){
    voiceBtn.className = `voice-button ${cls}`;
    const label = {
      idle:"Press to talk",
      listening:"Listening — tap to stop",
      thinking:"Processing…",
      speaking:"Speaking — tap to interrupt",
      error:"Error — tap to retry"
    }[cls] || "Press to talk";
    voiceBtn.setAttribute('aria-label', label);
  }

  // ---- Boot / iOS priming ----
  async function bootOnce(){
    if (hasBoot) return true;
    try{
      if(!audioCtx) audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      if(audioCtx.state!=='running') await audioCtx.resume();

      // prime output
      const buffer = audioCtx.createBuffer(1,1,audioCtx.sampleRate);
      const src = audioCtx.createBufferSource(); src.buffer=buffer; src.connect(audioCtx.destination); src.start(0);

      // prime HTMLAudio (iOS)
      const SILENCE = "data:audio/wav;base64,UklGRigAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA=";
      speaker.volume = 0.01; speaker.src = SILENCE; speaker.play().catch(()=>{}); speaker.pause(); speaker.currentTime = 0; speaker.volume = 1.0;

      // probe mic permissions
      const test = await navigator.mediaDevices.getUserMedia({ audio:{ echoCancellation:true, noiseSuppression:true, autoGainControl:true } });
      test.getTracks().forEach(t=>t.stop());

      hasBoot = true; memoryShadow.boot = true; saveLocal(memoryShadow);
      return true;
    }catch(e){
      console.log("Boot failed:", e);
      setBtnState('error');
      hasBoot=false;
      return false;
    }
  }

  async function ensureAudioContext(){
    if(!audioCtx) audioCtx = new (window.AudioContext||window.webkitAudioContext)();
    if(audioCtx.state!=='running') await audioCtx.resume();
  }

  function getPreferredMime(){
    const isiOS=/iPad|iPhone|iPod/.test(navigator.userAgent);
    const isSafari=/Safari/.test(navigator.userAgent)&&!/Chrome/.test(navigator.userAgent);
    if(isiOS||isSafari){
      if(MediaRecorder.isTypeSupported("audio/mp4;codecs=mp4a.40.2")) return "audio/mp4;codecs=mp4a.40.2";
      if(MediaRecorder.isTypeSupported("audio/mp4")) return "audio/mp4";
    } else {
      if(MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) return "audio/webm;codecs=opus";
      if(MediaRecorder.isTypeSupported("audio/webm")) return "audio/webm";
    }
    return "";
  }

  async function getMicStream(){
    const tries = [
      { audio:{ echoCancellation:true, noiseSuppression:true, autoGainControl:true, sampleRate:48000, channelCount:1 }, video:false },
      { audio:{ echoCancellation:true, noiseSuppression:true }, video:false },
      { audio:{ echoCancellation:true }, video:false },
      { audio:true, video:false }
    ];
    let lastErr;
    for(const c of tries){
      try{ return await navigator.mediaDevices.getUserMedia(c); }
      catch(e){ lastErr = e; }
    }
    throw lastErr || new Error("Microphone not available");
  }

  function stopSpeaker(){ try{ speaker.pause(); speaker.currentTime=0; isSpeaking=false; }catch{} }
  function cleanupAudioProcessing(){ clearTimeout(maxRecordTimer); try{audioProcessor?.disconnect();}catch{} audioProcessor=null; try{source?.disconnect();}catch{} source=null; }
  function cleanupMicrophone(){ cleanupAudioProcessing(); try{ micStream?.getTracks().forEach(t=>t.stop()); }catch{} micStream=null; }

  async function startListening(){
    if(isListening||isProcessing) return;
    try{
      isListening = true; setBtnState('listening');
      await ensureAudioContext();
      micStream = await getMicStream();

      const mime = getPreferredMime();
      const opts = {}; if(mime) opts.mimeType = mime;
      micRecorder = new MediaRecorder(micStream, opts);

      chunks = []; startedAt = performance.now(); lastNonSilenceAt = startedAt;

      micRecorder.ondataavailable = (e)=>{ if(e.data && e.data.size>0) chunks.push(e.data); };
      micRecorder.onstop = async ()=>{ isListening=false; await processRecording(); };
      micRecorder.onerror = (e)=>{ console.log('Recorder error:', e); isListening=false; cleanupMicrophone(); setBtnState('error'); };

      micRecorder.start(100);
      setupAudioProcessing();

      maxRecordTimer = setTimeout(()=>{ try{ if(micRecorder?.state==='recording') micRecorder.stop(); }catch{} }, 12000);
    }catch(e){
      console.log("Start listen failed:", e);
      setBtnState('error'); isListening=false; cleanupMicrophone();
    }
  }

  function setupAudioProcessing(){
    try{
      source = audioCtx.createMediaStreamSource(micStream);
      audioProcessor = audioCtx.createScriptProcessor(1024,1,1);
      let hasSpeech=false;
      const MIN_MS=500, LINGER_MS=1100, THRESH=0.0035;
      source.connect(audioProcessor); audioProcessor.connect(audioCtx.destination);
      audioProcessor.onaudioprocess = (ev)=>{
        if(!isListening) return;
        const data = ev.inputBuffer.getChannelData(0);
        let sum=0; for(let i=0;i<data.length;i++) sum+=Math.abs(data[i]);
        const avg = sum / data.length; const now = performance.now();
        if(avg>THRESH){ hasSpeech=true; lastNonSilenceAt=now; }
        const elapsed = now-startedAt, since = now-lastNonSilenceAt;
        if(hasSpeech && elapsed>MIN_MS && since>LINGER_MS){
          try{ if(micRecorder?.state==='recording') micRecorder.stop(); }catch{}
        }
      };
    }catch(e){ console.log("Audio processing setup error:", e); }
  }

  async function blobToBase64(blob){ return new Promise((res,rej)=>{ const r=new FileReader(); r.onloadend=()=>{ const s=String(r.result||""); res(s.split(",")[1]||"");}; r.onerror=()=>rej(r.error||new Error("readAsDataURL failed")); r.readAsDataURL(blob); }); }
  async function getAudioDuration(blob){ return new Promise(r=>{ const a=new Audio(); a.onloadedmetadata=()=>r(a.duration||0); a.onerror=()=>r(0); a.src=URL.createObjectURL(blob); }); }

  async function processRecording(){
    if(!isSession||isProcessing) return;
    try{
      isProcessing=true; setBtnState('thinking'); cleanupAudioProcessing();
      const blob=new Blob(chunks,{type:micRecorder?.mimeType||'audio/webm'}); chunks=[];
      if(!blob.size || blob.size<1500){ isProcessing=false; if(isSession) setTimeout(()=>startListening(),200); else setBtnState('idle'); return; }
      const duration=await getAudioDuration(blob);
      const b64 = await blobToBase64(blob);
      inflightController?.abort(); inflightController = new AbortController();

      const payload = {
        businessId: BIZ_ID,
        sessionId,
        memoryShadow,
        audio:{ data:b64, mime: blob.type||'audio/webm', originalSize: blob.size, processedSize: blob.size, duration }
      };

      const resp = await fetch('/.netlify/functions/voice',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload), signal:inflightController.signal });
      if(!resp.ok){ setBtnState('error'); console.log("Server error:", resp.status, resp.statusText); isProcessing=false; return; }
      const data = await resp.json();
      if(data.sessionId) sessionId = data.sessionId;
      if(data.memoryShadow){ memoryShadow = data.memoryShadow; saveLocal(memoryShadow); }

      if(data.control?.stopListening){ setBtnState('idle'); isProcessing=false; return; }
      if(!data.audio){ isProcessing=false; if(isSession) setTimeout(()=>startListening(),200); else setBtnState('idle'); return; }

      await playResponse(data.audio);
    }catch(e){
      console.log("Processing error:", e);
      setBtnState('error');
      if(isSession) setTimeout(()=>{ isProcessing=false; startListening(); }, 500); else isProcessing=false;
    }finally{ cleanupMicrophone(); }
  }

  async function playResponse(dataUrl){
    try{
      isSpeaking=true; setBtnState('speaking');
      await ensureAudioContext();
      await playViaWebAudio(dataUrl);
      isSpeaking=false; isProcessing=false;
      if(isSession){ setBtnState('listening'); setTimeout(()=>startListening(),150); } else setBtnState('idle');
    }catch{
      try{
        speaker.src=dataUrl; speaker.volume=1.0;
        await speaker.play();
        speaker.onended=()=>{ isSpeaking=false; isProcessing=false; if(isSession){ setBtnState('listening'); setTimeout(()=>startListening(),150);} else setBtnState('idle'); };
      }catch{
        isSpeaking=false; isProcessing=false; setBtnState('error'); if(isSession) setTimeout(()=>startListening(),300);
      }
    }
  }

  async function playViaWebAudio(dataUrl){
    await ensureAudioContext();
    let buf;
    try{ const r=await fetch(dataUrl); buf=await r.arrayBuffer(); }
    catch{ const b=dataUrl.split(",")[1]||""; const bytes=Uint8Array.from(atob(b),c=>c.charCodeAt(0)); buf=bytes.buffer; }
    const ab = await audioCtx.decodeAudioData(buf);
    const gain = audioCtx.createGain(); gain.gain.value = 1.15;
    await new Promise(res=>{
      const s=audioCtx.createBufferSource(); s.buffer=ab; s.connect(gain); gain.connect(audioCtx.destination);
      s.onended=res; s.start(0);
    });
  }

  function stopSession(){
    isSession=false; isListening=false; isProcessing=false;
    inflightController?.abort(); stopSpeaker();
    try{ if(micRecorder?.state==='recording') micRecorder.stop(); }catch{}
    cleanupMicrophone(); setBtnState('idle');
  }

  async function handleToggle(e){
    e.preventDefault(); if(uiLock) return; uiLock=true; voiceBtn.classList.add('pressed'); setTimeout(()=>voiceBtn.classList.remove('pressed'),120);
    try{
      if(!memoryShadow.boot || !hasBoot){ const ok = await bootOnce(); if(!ok){ uiLock=false; return; } await new Promise(r=>setTimeout(r,75)); }
      if(!isSession){ isSession=true; sessionId='nora_'+Date.now(); await startListening(); }
      else { stopSession(); }
    } catch(err){
      console.log("Toggle error:", err); setBtnState('error'); setTimeout(()=>{ if(!isSession) setBtnState('idle'); }, 900);
    } finally { setTimeout(()=>uiLock=false, 250); }
  }

  voiceBtn.addEventListener('click', handleToggle, { passive:false });
  voiceBtn.addEventListener('click', ()=>{ if(isSpeaking && isSession){ stopSpeaker(); } }, { passive:true });
  voiceBtn.addEventListener('keydown', (e)=>{ if(e.key==='Enter'||e.key===' '){ e.preventDefault(); handleToggle(e);} });

  setBtnState('idle');
})();
</script>
</body>
</html>
