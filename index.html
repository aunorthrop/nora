<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Senior Voice Assistant</title>
<style>
  *{margin:0;padding:0;box-sizing:border-box}
  html,body{height:100%}
  body{
    background:#f8f9fa;
    display:flex;align-items:center;justify-content:center;
    -webkit-user-select:none;user-select:none;
    font-family:-apple-system, BlinkMacSystemFont, "Inter", system-ui, sans-serif;
    touch-action:manipulation;
  }
  .wrapper{display:flex;flex-direction:column;gap:16px;align-items:center}
  .voice-button{
    width:160px;height:160px;border:none;border-radius:32px;background:#fff;
    box-shadow:0 4px 16px rgba(0,0,0,.1), inset 0 -3px 0 rgba(0,0,0,.06);
    cursor:pointer;position:relative;
    transition:transform .06s ease, box-shadow .06s ease, background .15s ease, color .15s ease;
    color:#1a1a1a;-webkit-tap-highlight-color:transparent;
    font-size:14px;font-weight:500
  }
  .voice-button:active,.voice-button.pressed{transform:scale(.98);box-shadow:inset 0 4px 12px rgba(0,0,0,.2),0 2px 4px rgba(0,0,0,.05)}
  .voice-button.idle{background:#fff;color:#1a1a1a}
  .voice-button.listening{background:#007AFF;color:#fff;box-shadow:0 0 0 4px rgba(0,122,255,.2), 0 4px 16px rgba(0,0,0,.15)}
  .voice-button.thinking{background:#FFCC00;color:#1a1a1a}
  .voice-button.speaking{background:#34C759;color:#fff}
  .voice-button.error{background:#FF3B30;color:#fff}
  .mic-icon{width:32px;height:32px;fill:currentColor}
  label{font-size:14px;color:#333}
  input[type="text"]{padding:8px 10px;border:1px solid #ddd;border-radius:8px;width:320px;max-width:80vw}
  .row{display:flex;gap:8px;align-items:center;flex-wrap:wrap;justify-content:center}
  @media (prefers-reduced-motion: reduce) { .voice-button { transition: none; } }
  @media (max-width: 480px) { .voice-button { width: 180px; height: 180px; } .mic-icon { width: 36px; height: 36px; } }
</style>
</head>
<body>
  <div class="wrapper">
    <div class="row">
      <label for="elevenId">ElevenLabs Voice ID:</label>
      <input id="elevenId" type="text" placeholder="Paste your Voice ID (not name)"/>
      <button id="saveVoice" style="padding:8px 12px;border:0;border-radius:8px;background:#eee;cursor:pointer">Save</button>
    </div>

    <button id="voiceBtn" class="voice-button idle" aria-label="Voice Assistant - Press to talk" title="TTS: unknown">
      <svg class="mic-icon" viewBox="0 0 24 24" aria-hidden="true">
        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm7-3h-2a5 5 0 0 1-10 0H5a7 7 0 0 0 6 6.92V21h2v-3.08A7 7 0 0 0 19 11z"/>
      </svg>
    </button>
  </div>

  <input id="bizId" type="hidden" value="senior-assistant"/>

<script>
(() => {
  const voiceBtn = document.getElementById('voiceBtn');
  const saveBtn = document.getElementById('saveVoice');
  const elevenInput = document.getElementById('elevenId');
  const BIZ_ID = (document.getElementById('bizId').value || 'senior-assistant');

  // Debug (iOS Safari)
  console.log('iOS:', /iPad|iPhone|iPod/.test(navigator.userAgent));
  console.log('Safari:', /Safari/.test(navigator.userAgent) && !/Chrome/.test(navigator.userAgent));

  // Persistent local memory
  const LOCAL_KEY = `senior_voice_memory_${BIZ_ID}`;
  function loadLocal(){ 
    try { 
      return JSON.parse(localStorage.getItem(LOCAL_KEY) || '{"items":[],"conversations":[],"voice":"alloy","pace":0.85,"boot":false}'); 
    } catch { 
      return {items:[],conversations:[],voice:"alloy",pace:0.85,boot:false}; 
    } 
  }
  function saveLocal(m){ try { localStorage.setItem(LOCAL_KEY, JSON.stringify(m)); } catch(e) { console.log('Storage error:', e); } }

  let memoryShadow = loadLocal(); 
  memoryShadow.voice = "alloy"; 
  memoryShadow.pace = memoryShadow.pace || 0.85;
  if (!memoryShadow.conversations) memoryShadow.conversations = [];
  if (!memoryShadow.elevenVoiceId) memoryShadow.elevenVoiceId = "";  // NEW
  saveLocal(memoryShadow);

  // Populate voice ID input
  elevenInput.value = memoryShadow.elevenVoiceId || "";

  saveBtn.addEventListener('click', () => {
    memoryShadow.elevenVoiceId = (elevenInput.value || "").trim();
    saveLocal(memoryShadow);
    saveBtn.textContent = "Saved";
    setTimeout(() => saveBtn.textContent = "Save", 1000);
  });

  // State
  let isSessionActive=false,isListening=false,isProcessing=false,isSpeaking=false;
  let sessionId=null,inflightController=null;
  let audioCtx,micStream,micRecorder,chunks=[];
  let audioProcessor,source,maxRecordTimer;
  let startedAt=0,lastNonSilenceAt=0,audioPrimed=false,uiLock=false, hasBoot=false;

  const speaker = new Audio(); 
  speaker.preload="none"; 
  speaker.playsInline=true;
  speaker.volume = 1.0;

  function setBtnState(cls){ 
    voiceBtn.className = `voice-button ${cls}`;
    const labels = {
      idle: 'Voice Assistant - Press to start talking',
      listening: 'Listening - Press to stop',
      thinking: 'Processing your message...',
      speaking: 'Speaking - Press to interrupt',
      error: 'Error occurred - Press to try again'
    };
    voiceBtn.setAttribute('aria-label', labels[cls] || labels.idle);
  }

  async function bootOnce(){
    if(hasBoot) return true;
    try{
      if(!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      if(audioCtx.state !== 'running') await audioCtx.resume();

      // Prime WebAudio + HTMLAudio
      const buffer = audioCtx.createBuffer(1, 1, audioCtx.sampleRate);
      const src = audioCtx.createBufferSource(); src.buffer = buffer; src.connect(audioCtx.destination); src.start(0);
      const SILENCE = "data:audio/wav;base64,UklGRigAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA=";
      speaker.volume = 0.01; speaker.src = SILENCE; speaker.play().catch(()=>{}); speaker.pause(); speaker.currentTime = 0; speaker.volume = 1.0;

      // Probe mic permissions
      const testStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true } });
      testStream.getTracks().forEach(t => t.stop());

      hasBoot = true;
      memoryShadow.boot = true; saveLocal(memoryShadow);
      return true;
    } catch(e) {
      console.log('Boot failed:', e);
      setBtnState('error');
      setTimeout(() => { if(!isSessionActive) setBtnState('idle'); }, 1500);
      hasBoot = false;
      return false;
    }
  }

  async function ensureAudioContext(){
    if(!audioCtx) audioCtx=new (window.AudioContext||window.webkitAudioContext)();
    if(audioCtx.state!=='running') await audioCtx.resume();
  }

  function getPreferredMime(){
    const isiOS=/iPad|iPhone|iPod/.test(navigator.userAgent);
    const isSafari=/Safari/.test(navigator.userAgent)&&!/Chrome/.test(navigator.userAgent);
    if(isiOS||isSafari){
      if(MediaRecorder.isTypeSupported("audio/mp4;codecs=mp4a.40.2")) return "audio/mp4;codecs=mp4a.40.2";
      if(MediaRecorder.isTypeSupported("audio/mp4")) return "audio/mp4";
    } else {
      if(MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) return "audio/webm;codecs=opus";
      if(MediaRecorder.isTypeSupported("audio/webm")) return "audio/webm";
    }
    return "";
  }

  async function getMicStreamWithFallback(){
    const tries = [
      { audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true, sampleRate:48000, channelCount:1 }, video:false },
      { audio: { echoCancellation:true, noiseSuppression:true }, video:false },
      { audio: { echoCancellation:true }, video:false },
      { audio: true, video:false }
    ];
    let lastErr;
    for (const c of tries){
      try { return await navigator.mediaDevices.getUserMedia(c); }
      catch(e){ lastErr=e; console.log('Mic constraint failed:', c, e); }
    }
    throw lastErr || new Error("getUserMedia failed");
  }

  function stopSpeaker(){ try{speaker.pause();speaker.currentTime=0;isSpeaking=false;}catch{} }
  function cleanupAudioProcessing(){ clearTimeout(maxRecordTimer); try{audioProcessor?.disconnect();}catch{} audioProcessor=null; try{source?.disconnect();}catch{} source=null; }
  function cleanupMicrophone(){ cleanupAudioProcessing(); try{ micStream?.getTracks().forEach(t=>t.stop()); }catch{} micStream=null; }

  async function startListening(){
    if(isListening || isProcessing) return;
    try {
      isListening = true; setBtnState('listening');
      if(!audioCtx || audioCtx.state !== 'running') await ensureAudioContext();

      micStream = await getMicStreamWithFallback();
      const mime = getPreferredMime();
      const recorderOptions = {}; if(mime) recorderOptions.mimeType = mime;
      micRecorder = new MediaRecorder(micStream, recorderOptions);

      chunks = []; startedAt = performance.now(); lastNonSilenceAt = startedAt;

      micRecorder.ondataavailable = (e) => { if(e.data && e.data.size > 0) chunks.push(e.data); };
      micRecorder.onstop = async () => { isListening = false; await processRecording(); };
      micRecorder.onerror = (e) => { console.log('MediaRecorder error:', e); isListening=false; cleanupMicrophone(); setBtnState('error'); };

      micRecorder.start(100);
      setupAudioProcessing();

      maxRecordTimer = setTimeout(() => {
        if(micRecorder && micRecorder.state === 'recording') { try { micRecorder.stop(); } catch(e) {} }
      }, 12000);
    } catch(error) {
      console.log('Start listening error:', error);
      setBtnState('error');
      setTimeout(() => { if(!isSessionActive) setBtnState('idle'); }, 1500);
      isListening = false; cleanupMicrophone();
    }
  }

  function setupAudioProcessing(){
    try {
      source = audioCtx.createMediaStreamSource(micStream);
      audioProcessor = audioCtx.createScriptProcessor(1024, 1, 1);
      let hasSpeech = false;
      const MIN_MS = 500, LINGER_MS = 1200, THRESH = 0.003;

      source.connect(audioProcessor); audioProcessor.connect(audioCtx.destination);
      audioProcessor.onaudioprocess = (ev) => {
        if(!isListening) return;
        const data = ev.inputBuffer.getChannelData(0);
        let sum = 0; for(let i=0;i<data.length;i++) sum += Math.abs(data[i]);
        const avg = sum / data.length;
        const now = performance.now();
        if(avg > THRESH){ hasSpeech = true; lastNonSilenceAt = now; }
        const elapsed = now - startedAt; const since = now - lastNonSilenceAt;
        if(hasSpeech && elapsed > MIN_MS && since > LINGER_MS){
          try { if(micRecorder.state === 'recording') micRecorder.stop(); } catch(e){}
        }
      };
    } catch(e) { console.log('Audio processing setup error:', e); }
  }

  async function blobToBase64(blob){ return new Promise((res,rej)=>{ const r=new FileReader(); r.onloadend=()=>{ const s=String(r.result||""); res(s.split(",")[1]||"");}; r.onerror=()=>rej(r.error||new Error("readAsDataURL failed")); r.readAsDataURL(blob); }); }
  async function getAudioDuration(blob){ return new Promise(r=>{ const a=new Audio(); a.onloadedmetadata=()=>r(a.duration||0); a.onerror=()=>r(0); a.src=URL.createObjectURL(blob); }); }

  async function processRecording(){
    if(!isSessionActive||isProcessing) return;
    try{
      isProcessing=true; setBtnState('thinking'); cleanupAudioProcessing();
      const blob=new Blob(chunks,{type:micRecorder?.mimeType||'audio/webm'}); chunks=[];
      if(!blob.size||blob.size<1500){ isProcessing=false; if(isSessionActive) setTimeout(()=>startListening(),200); else setBtnState('idle'); return; }

      const duration=await getAudioDuration(blob);
      const b64=await blobToBase64(blob);
      inflightController?.abort(); inflightController=new AbortController();

      const payload={ 
        businessId: BIZ_ID, 
        sessionId, 
        memoryShadow,
        // Force ElevenLabs; pass per-turn voiceId from local settings
        tts: { engine: "eleven", voiceId: (memoryShadow.elevenVoiceId || "").trim() || undefined },
        audio: { data: b64, mime: blob.type||'audio/webm', originalSize: blob.size, processedSize: blob.size, duration }
      };
      
      const resp=await fetch('/.netlify/functions/voice',{ 
        method:'POST', headers:{'Content-Type':'application/json'}, 
        body:JSON.stringify(payload), signal:inflightController.signal 
      });
      
      if(!resp.ok){ 
        console.log('Server error:', resp.status, resp.statusText);
        setBtnState('error'); 
        setTimeout(()=>{ if(!isSessionActive) setBtnState('idle'); }, 1500); 
        isProcessing=false; return; 
      }
      
      const data=await resp.json();
      console.log('Server response:', data);

      // Display engine + possible server error message
      if (data.ttsEngine) {
        console.log("[TTS ENGINE]", data.ttsEngine);
        voiceBtn.title = `TTS: ${data.ttsEngine}`;
      }
      if (data.error) {
        console.warn("[SERVER ERROR]", data.error);
      }

      if(data.sessionId) sessionId=data.sessionId;
      if(data.memoryShadow){ memoryShadow=data.memoryShadow; saveLocal(memoryShadow); }

      if(data.control?.stopListening){ setBtnState('idle'); isProcessing=false; return; }
      if(!data.audio){ isProcessing=false; if(isSessionActive) setTimeout(()=>startListening(),200); else setBtnState('idle'); return; }

      await playResponse(data.audio);
    }catch(e){
      console.log('Processing error:', e);
      setBtnState('error'); 
      if(isSessionActive) setTimeout(()=>{ isProcessing=false; startListening(); }, 500); else { isProcessing=false; }
    }finally{ cleanupMicrophone(); }
  }

  async function playResponse(dataUrl){
    try{
      isSpeaking=true; setBtnState('speaking');
      await ensureAudioContext();
      await playViaWebAudio(dataUrl); 
      isSpeaking=false; isProcessing=false;
      if(isSessionActive){ setBtnState('listening'); setTimeout(()=>startListening(), 150); }
      else setBtnState('idle');
    }catch(waErr){
      try{ 
        speaker.src=dataUrl; speaker.volume = 1.0; await speaker.play();
        speaker.onended=()=>{ isSpeaking=false; isProcessing=false; if(isSessionActive){ setBtnState('listening'); setTimeout(()=>startListening(), 150);} else setBtnState('idle'); };
      }catch{ 
        isSpeaking=false; isProcessing=false; setBtnState('error'); if(isSessionActive) setTimeout(()=>startListening(), 300); 
      }
    }
  }

  async function playViaWebAudio(dataUrl){
    await ensureAudioContext(); 
    let buf;
    try{ const r=await fetch(dataUrl); buf=await r.arrayBuffer(); }
    catch{ const b=dataUrl.split(",")[1]||""; const bytes=Uint8Array.from(atob(b),c=>c.charCodeAt(0)); buf=bytes.buffer; }
    const ab = await audioCtx.decodeAudioData(buf);
    const gainNode = audioCtx.createGain(); gainNode.gain.value = 1.2;
    await new Promise(res=>{ const s=audioCtx.createBufferSource(); s.buffer=ab; s.connect(gainNode); gainNode.connect(audioCtx.destination); s.onended=res; s.start(0); });
  }

  function stopSession(){
    isSessionActive=false; isListening=false; isProcessing=false;
    inflightController?.abort(); stopSpeaker();
    try{ if(micRecorder?.state==='recording') micRecorder.stop(); }catch{}
    cleanupMicrophone(); setBtnState('idle');
  }

  async function handleToggle(e){
    e.preventDefault();
    if(voiceBtn.classList.contains('pressed')) return;
    voiceBtn.classList.add('pressed');
    setTimeout(()=>voiceBtn.classList.remove('pressed'),120);
    try{
      if(!memoryShadow.boot || !hasBoot){
        const ok = await bootOnce(); if(!ok) return;
        await new Promise(r=>setTimeout(r,75));
      }
      if(!isSessionActive){ isSessionActive=true; sessionId='senior_session_'+Date.now(); await startListening(); }
      else { stopSession(); }
    }catch(err){
      console.log('Toggle error:', err);
      setBtnState('error'); setTimeout(()=>{ if(!isSessionActive) setBtnState('idle'); }, 1000);
    }
  }

  voiceBtn.addEventListener('click', handleToggle, { passive:false });
  voiceBtn.addEventListener('click', () => { if(isSpeaking && isSessionActive){ stopSpeaker(); } }, { passive:true });
  voiceBtn.addEventListener('keydown', (e) => { if (e.key === 'Enter' || e.key === ' ') { e.preventDefault(); handleToggle(e); } });

  console.log('Senior Voice Assistant UI initialized');
})();
</script>
</body>
</html>
